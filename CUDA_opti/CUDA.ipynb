{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np \n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_host = np.ones(shape=(1048575))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_inc_one(arr):\n",
    "    for i  in range(arr.shape[0]):\n",
    "        arr[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "host_inc_one(x_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit()\n",
    "def device_inc_one(arr):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < arr.size:\n",
    "        arr[pos] += 1\n",
    "\n",
    "\n",
    "x_device = cuda.to_device(x_host)\n",
    "print(x_device.size)\n",
    "threadsperblock = 256\n",
    "blockspergrid = (x_device.size + (threadsperblock - 1)) // threadsperblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "device_inc_one[blockspergrid,threadsperblock](x_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_device.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_device = cuda.to_device(np.ones(shape=(256,256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def device_inc_one_2d(arr):\n",
    "    x,y = cuda.grid(2)\n",
    "    if(x<arr.shape[0] and y<arr.shape[1]):\n",
    "        arr[x,y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadsperblock = (8,8)\n",
    "blockspergrid_x = math.ceil(x_device.shape[0]/threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(x_device.shape[1]/threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "device_inc_one_2d[blockspergrid,threadsperblock](x_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "for obj in b[0]:\n",
    "    obj+=1\n",
    "    print(obj)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import os\n",
    "# 設置 CUDA 可見設備\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# 列出所有可用的 GPU\n",
    "print(\"Available GPUs:\", cuda.gpus)\n",
    "\n",
    "# 嘗試選擇 GPU 1\n",
    "try:\n",
    "    cuda.select_device(1)\n",
    "    print(\"Selected GPU 1\")\n",
    "except cuda.cudadrv.error.CudaSupportError as e:\n",
    "    print(\"Failed to select GPU 1:\", e)\n",
    "\n",
    "# 確認當前選擇的 GPU\n",
    "print(cuda.get_current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_arr = [30, 0.3, 0.1, 1]\n",
    "x = 1\n",
    "r = 5\n",
    "(-x/(r**2)) * config_arr[0]*config_arr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import concurrent.futures\n",
    "\n",
    "@cuda.jit\n",
    "def update_cuda(board):\n",
    "    x,y = cuda.grid(2)\n",
    "    r = ((0-x)**2 + (0-y)**2)\n",
    "    if(r < 25):\n",
    "        board[x][y][0] += 1\n",
    "        board[x][y][1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x0000020B579E24E0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mother_board = np.zeros(shape=(800,600,7),dtype='float32') # 800x600 x 每單位資料(force x, force y, velocity x, velocity y)\n",
    "device_board = cuda.to_device(mother_board)\n",
    "threadsperblock = (32,32)\n",
    "blockspergrid_x = math.ceil(device_board.shape[0]/threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(device_board.shape[1]/threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(update_cuda[blockspergrid,threadsperblock](device_board), [i for i in range(500)]) \n",
    "for _ in range(500):\n",
    "    update_cuda[blockspergrid,threadsperblock](device_board)\n",
    "temp = device_board[0]\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.30.7, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import pygame as pg \n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import os \n",
    "os.environ[\"PYGAME_DETECT_AVX2\"] = \"1\"\n",
    "\n",
    "class temp:\n",
    "    def __init__(self):\n",
    "        self.x = 1\n",
    "    \n",
    "\n",
    "\n",
    "@cuda.jit()\n",
    "def device_inc_one(arr):\n",
    "    pos = cuda.grid(1)\n",
    "\n",
    "\n",
    "a = temp()\n",
    "b = temp()\n",
    "x_host = [a,b]\n",
    "\n",
    "x_device = cuda.to_device(x_host)\n",
    "print(x_device.size)\n",
    "threadsperblock = 256\n",
    "blockspergrid = (x_device.size + (threadsperblock - 1)) // threadsperblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in cuda mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\Kaijin\\AppData\\Local\\Temp\\ipykernel_22168\\3436628903.py (13)\u001b[0m\n\u001b[1m\nFile \"C:\\Users\\Kaijin\\AppData\\Local\\Temp\\ipykernel_22168\\3436628903.py\", line 13:\u001b[0m\n\u001b[1m    def __init__(self):\n        <source elided>\n\n\u001b[1m@cuda.jit()\n\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device_inc_one[blockspergrid,threadsperblock](x_device)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:539\u001b[0m, in \u001b[0;36m_LaunchConfiguration.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher\u001b[38;5;241m.\u001b[39mcall(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgriddim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblockdim,\n\u001b[0;32m    540\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharedmem)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:681\u001b[0m, in \u001b[0;36mCUDADispatcher.call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    679\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 681\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m _dispatcher\u001b[38;5;241m.\u001b[39mDispatcher\u001b[38;5;241m.\u001b[39m_cuda_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    683\u001b[0m kernel\u001b[38;5;241m.\u001b[39mlaunch(args, griddim, blockdim, stream, sharedmem)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:689\u001b[0m, in \u001b[0;36mCUDADispatcher._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kws\n\u001b[0;32m    688\u001b[0m argtypes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeof_pyval(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;28mtuple\u001b[39m(argtypes))\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:932\u001b[0m, in \u001b[0;36mCUDADispatcher.compile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_compile:\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilation disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 932\u001b[0m kernel \u001b[38;5;241m=\u001b[39m _Kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_func, argtypes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetoptions)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# We call bind to force codegen, so that there is a cubin to cache\u001b[39;00m\n\u001b[0;32m    934\u001b[0m kernel\u001b[38;5;241m.\u001b[39mbind()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:83\u001b[0m, in \u001b[0;36m_Kernel.__init__\u001b[1;34m(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m nvvm_options \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastmath\u001b[39m\u001b[38;5;124m'\u001b[39m: fastmath,\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     80\u001b[0m }\n\u001b[0;32m     82\u001b[0m cc \u001b[38;5;241m=\u001b[39m get_current_device()\u001b[38;5;241m.\u001b[39mcompute_capability\n\u001b[1;32m---> 83\u001b[0m cres \u001b[38;5;241m=\u001b[39m compile_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_func, types\u001b[38;5;241m.\u001b[39mvoid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margtypes,\n\u001b[0;32m     84\u001b[0m                     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug,\n\u001b[0;32m     85\u001b[0m                     lineinfo\u001b[38;5;241m=\u001b[39mlineinfo,\n\u001b[0;32m     86\u001b[0m                     inline\u001b[38;5;241m=\u001b[39minline,\n\u001b[0;32m     87\u001b[0m                     fastmath\u001b[38;5;241m=\u001b[39mfastmath,\n\u001b[0;32m     88\u001b[0m                     nvvm_options\u001b[38;5;241m=\u001b[39mnvvm_options,\n\u001b[0;32m     89\u001b[0m                     cc\u001b[38;5;241m=\u001b[39mcc)\n\u001b[0;32m     90\u001b[0m tgt_ctx \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[0;32m     91\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\cuda\\compiler.py:196\u001b[0m, in \u001b[0;36mcompile_cuda\u001b[1;34m(pyfunc, return_type, args, debug, lineinfo, inline, fastmath, nvvm_options, cc)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m target_override\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m target_override(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 196\u001b[0m     cres \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mcompile_extra(typingctx\u001b[38;5;241m=\u001b[39mtypingctx,\n\u001b[0;32m    197\u001b[0m                                   targetctx\u001b[38;5;241m=\u001b[39mtargetctx,\n\u001b[0;32m    198\u001b[0m                                   func\u001b[38;5;241m=\u001b[39mpyfunc,\n\u001b[0;32m    199\u001b[0m                                   args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    200\u001b[0m                                   return_type\u001b[38;5;241m=\u001b[39mreturn_type,\n\u001b[0;32m    201\u001b[0m                                   flags\u001b[38;5;241m=\u001b[39mflags,\n\u001b[0;32m    202\u001b[0m                                   \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    203\u001b[0m                                   pipeline_class\u001b[38;5;241m=\u001b[39mCUDACompiler)\n\u001b[0;32m    205\u001b[0m library \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39mlibrary\n\u001b[0;32m    206\u001b[0m library\u001b[38;5;241m.\u001b[39mfinalize()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler.py:744\u001b[0m, in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \n\u001b[0;32m    722\u001b[0m \u001b[38;5;124;03mParameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    compiler pipeline\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    742\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    743\u001b[0m                           args, return_type, flags, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[1;32m--> 744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39mcompile_extra(func)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler.py:438\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_bytecode()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler.py:506\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfunc_ir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_core()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler.py:485\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mfail_reason \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_final_pipeline:\n\u001b[1;32m--> 485\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompilerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll available pipelines exhausted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler.py:472\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m     pm\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:368\u001b[0m, in \u001b[0;36mPassManager.run\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    365\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m mode pipeline (step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \\\n\u001b[0;32m    366\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name, pass_desc)\n\u001b[0;32m    367\u001b[0m patched_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_patch_error(msg, e)\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m patched_exception\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    354\u001b[0m pass_inst \u001b[38;5;241m=\u001b[39m _pass_registry\u001b[38;5;241m.\u001b[39mget(pss)\u001b[38;5;241m.\u001b[39mpass_inst\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runPass(idx, pass_inst, state)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegacy pass in use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[1;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[0;32m    309\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_initialization, internal_state)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m pass_time:\n\u001b[1;32m--> 311\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_pass, internal_state)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m finalize_time:\n\u001b[0;32m    313\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[1;34m(func, compiler_state)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(func, compiler_state):\n\u001b[1;32m--> 273\u001b[0m     mangled \u001b[38;5;241m=\u001b[39m func(compiler_state)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mangled \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass implementations should return True/False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m did not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\typed_passes.py:112\u001b[0m, in \u001b[0;36mBaseTypeInference.run_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mType inference and legalization\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fallback_context(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m failed type inference\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    110\u001b[0m                       \u001b[38;5;241m%\u001b[39m (state\u001b[38;5;241m.\u001b[39mfunc_id\u001b[38;5;241m.\u001b[39mfunc_name,)):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Type inference\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     typemap, return_type, calltypes, errs \u001b[38;5;241m=\u001b[39m type_inference_stage(\n\u001b[0;32m    113\u001b[0m         state\u001b[38;5;241m.\u001b[39mtypingctx,\n\u001b[0;32m    114\u001b[0m         state\u001b[38;5;241m.\u001b[39mtargetctx,\n\u001b[0;32m    115\u001b[0m         state\u001b[38;5;241m.\u001b[39mfunc_ir,\n\u001b[0;32m    116\u001b[0m         state\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    117\u001b[0m         state\u001b[38;5;241m.\u001b[39mreturn_type,\n\u001b[0;32m    118\u001b[0m         state\u001b[38;5;241m.\u001b[39mlocals,\n\u001b[0;32m    119\u001b[0m         raise_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_errors)\n\u001b[0;32m    120\u001b[0m     state\u001b[38;5;241m.\u001b[39mtypemap \u001b[38;5;241m=\u001b[39m typemap\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# save errors in case of partial typing\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\typed_passes.py:93\u001b[0m, in \u001b[0;36mtype_inference_stage\u001b[1;34m(typingctx, targetctx, interp, args, return_type, locals, raise_errors)\u001b[0m\n\u001b[0;32m     91\u001b[0m     infer\u001b[38;5;241m.\u001b[39mbuild_constraint()\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# return errors in case of partial typing\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     errs \u001b[38;5;241m=\u001b[39m infer\u001b[38;5;241m.\u001b[39mpropagate(raise_errors\u001b[38;5;241m=\u001b[39mraise_errors)\n\u001b[0;32m     94\u001b[0m     typemap, restype, calltypes \u001b[38;5;241m=\u001b[39m infer\u001b[38;5;241m.\u001b[39munify(raise_errors\u001b[38;5;241m=\u001b[39mraise_errors)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _TypingResults(typemap, restype, calltypes, errs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\AI_intro\\Lib\\site-packages\\numba\\core\\typeinfer.py:1091\u001b[0m, in \u001b[0;36mTypeInferer.propagate\u001b[1;34m(self, raise_errors)\u001b[0m\n\u001b[0;32m   1088\u001b[0m force_lit_args \u001b[38;5;241m=\u001b[39m [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m errors\n\u001b[0;32m   1089\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ForceLiteralArg)]\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_lit_args:\n\u001b[1;32m-> 1091\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reduce(operator\u001b[38;5;241m.\u001b[39mor_, force_lit_args)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in cuda mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type array(pyobject, 1d, C)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\Kaijin\\AppData\\Local\\Temp\\ipykernel_22168\\3436628903.py (13)\u001b[0m\n\u001b[1m\nFile \"C:\\Users\\Kaijin\\AppData\\Local\\Temp\\ipykernel_22168\\3436628903.py\", line 13:\u001b[0m\n\u001b[1m    def __init__(self):\n        <source elided>\n\n\u001b[1m@cuda.jit()\n\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device_inc_one[blockspergrid,threadsperblock](x_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
